{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from datetime import datetime\n",
    "import re\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local[4]\").setAppName(\"transport\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filename(raw_name):\n",
    "    day, from_day, to_day = re.findall(r'\\d+', raw_name)\n",
    "    return \"day=%s/from=%s/to=%s\" % (day, from_day, to_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_files(compressed_name, stream):\n",
    "    \"\"\"\n",
    "    Extract .csv files from a .zip file and load in different DataFrames.\n",
    "    \"\"\"\n",
    "    with BytesIO(stream) as tf:\n",
    "        tf.seek(0)        \n",
    "        # Read the file as a zipfile and process the members\n",
    "        try:            \n",
    "            with ZipFile(tf, mode='r') as zipf:\n",
    "                return [(build_filename(compressed_name + file_name), zipf.read(file_name)) for file_name in zipf.namelist()]\n",
    "        except:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime.strptime(row[0], \"%d/%m/%Y %H:%M:%S\")\n",
    "def prepare_csv(file_name, table):\n",
    "    return list(map(lambda row: [file_name, datetime.strptime(row[0], \"%d/%m/%Y %H:%M:%S\"), int(row[1]), \n",
    "                                 row[2], int(row[3]), row[4], \n",
    "                                 row[5]], table)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) PythonRDD[1] at RDD at PythonRDD.scala:53 []\n",
      " |  datasets/test-folder.small/*.zip BinaryFileRDD[0] at binaryFiles at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "path = 'datasets/test-folder.small/*.zip'\n",
    "rdd = sc.binaryFiles(path).flatMap(lambda a: extract_files(a[0], a[1]))\n",
    "print(rdd.toDebugString().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode bytes and convert it in a list of strings\n",
    "rdd = rdd.mapValues(lambda file: BytesIO(file).read().decode('cp1252').split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string row to list row\n",
    "rdd = rdd.mapValues(lambda a: list(map(lambda row: row.split(\";\")[:-1], a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop header and last (and empty) row\n",
    "rdd = rdd.mapValues(lambda table: table[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change type of columns\n",
    "rdd = rdd.flatMap(lambda a: prepare_csv(a[0], a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['FILE_NAME',\n",
    "            'FECHAHORATRX',\n",
    "            'CODIGOENTIDAD',\n",
    "            'NOMBREENTIDAD',\n",
    "            'CODIGOSITIO',\n",
    "            'NOMBRESITIO',\n",
    "            'NROTARJETA']\n",
    "header = list(map(lambda a: a.lower(), header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 232 ms, sys: 2.47 ms, total: 234 ms\n",
      "Wall time: 2.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = rdd.toDF(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- file_name: string (nullable = true)\n",
      " |-- fechahoratrx: timestamp (nullable = true)\n",
      " |-- codigoentidad: long (nullable = true)\n",
      " |-- nombreentidad: string (nullable = true)\n",
      " |-- codigositio: long (nullable = true)\n",
      " |-- nombresitio: string (nullable = true)\n",
      " |-- nrotarjeta: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------+-------------+-----------+-----------+--------------------+\n",
      "|           file_name|       fechahoratrx|codigoentidad|nombreentidad|codigositio|nombresitio|          nrotarjeta|\n",
      "+--------------------+-------------------+-------------+-------------+-----------+-----------+--------------------+\n",
      "|day=20190311/from...|2019-03-01 01:20:44|           16|    U3 - Vule|       2308|    BJFZ-75|37d3a2cd6ba280f3a...|\n",
      "|day=20190311/from...|2019-03-01 01:20:47|           16|    U3 - Vule|       2308|    BJFZ-75|7464f0fb6fe00e347...|\n",
      "|day=20190311/from...|2019-03-01 01:20:50|           16|    U3 - Vule|       2308|    BJFZ-75|3ce1dbdd2d904a953...|\n",
      "|day=20190311/from...|2019-03-01 01:20:53|           16|    U3 - Vule|       2308|    BJFZ-75|dd9730ec384f81487...|\n",
      "|day=20190311/from...|2019-03-01 01:21:00|           16|    U3 - Vule|       2308|    BJFZ-75|7f4ded632ab214988...|\n",
      "|day=20190311/from...|2019-03-01 01:21:06|           16|    U3 - Vule|       2308|    BJFZ-75|0a9c6837b38eddffb...|\n",
      "|day=20190311/from...|2019-03-01 01:21:10|           16|    U3 - Vule|       2308|    BJFZ-75|8ff9b3bc9e2957085...|\n",
      "|day=20190311/from...|2019-03-01 01:21:17|           16|    U3 - Vule|       2308|    BJFZ-75|7b65ee8a7408d851f...|\n",
      "|day=20190311/from...|2019-03-01 01:21:26|           16|    U3 - Vule|       2308|    BJFZ-75|4ef9c1cf9d848f137...|\n",
      "|day=20190311/from...|2019-03-01 01:21:29|           16|    U3 - Vule|       2308|    BJFZ-75|1a2a31c723a20a365...|\n",
      "|day=20190311/from...|2019-03-01 01:21:37|           16|    U3 - Vule|       2308|    BJFZ-75|1a2a31c723a20a365...|\n",
      "|day=20190311/from...|2019-03-01 01:21:41|           16|    U3 - Vule|       2308|    BJFZ-75|508419763a017f0b6...|\n",
      "|day=20190311/from...|2019-03-01 01:21:47|           16|    U3 - Vule|       2308|    BJFZ-75|8c00b5c113dd844d9...|\n",
      "|day=20190311/from...|2019-03-01 01:33:59|           16|    U3 - Vule|       2308|    BJFZ-75|7a630b162211385be...|\n",
      "|day=20190311/from...|2019-03-01 02:15:13|           16|    U3 - Vule|      12599|    CJRX-70|dc795033753b7643d...|\n",
      "|day=20190311/from...|2019-03-01 02:18:08|           16|    U3 - Vule|      12599|    CJRX-70|bdf13a89c0bf57dfe...|\n",
      "|day=20190311/from...|2019-03-01 04:32:32|           16|    U3 - Vule|      12599|    CJRX-70|d52b9b967be059567...|\n",
      "|day=20190311/from...|2019-03-01 04:44:30|           16|    U3 - Vule|      12599|    CJRX-70|c67ff2c46ce34bea3...|\n",
      "|day=20190311/from...|2019-03-01 04:48:44|           16|    U3 - Vule|      12599|    CJRX-70|a71c753919b950c14...|\n",
      "|day=20190311/from...|2019-03-01 04:48:47|           16|    U3 - Vule|      12599|    CJRX-70|378189ec03150409b...|\n",
      "+--------------------+-------------------+-------------+-------------+-----------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 1.99 ms, sys: 0 ns, total: 1.99 ms\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 ms, sys: 0 ns, total: 1.2 ms\n",
      "Wall time: 2.34 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 ms, sys: 10.2 ms, total: 28.9 ms\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "days = [file.file_name for file in df.select('file_name').distinct().collect()]\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           file_name|count|\n",
      "+--------------------+-----+\n",
      "|day=20190311/from...|   99|\n",
      "|day=20180818/from...|   99|\n",
      "+--------------------+-----+\n",
      "\n",
      "CPU times: user 18.5 ms, sys: 7.1 ms, total: 25.6 ms\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.groupBy('file_name').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.01 ms, sys: 4.72 ms, total: 10.7 ms\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for directory in days:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    df_day = df.select(df.columns[1:]).where(df.file_name == directory)\n",
    "    df_day.write.parquet(directory + \"/data.parquet\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day=20190311/from=20190307/to=20190309=99\n",
      "day=20180818/from=20180812/to=20180814=99\n",
      "CPU times: user 9.37 ms, sys: 1.58 ms, total: 11 ms\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for directory in days:\n",
    "    print(\"%s=%d\" % (directory, df.select(df.columns[1:]).where(df.file_name == directory).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- file_name: string (nullable = true)\n",
      " |-- fechahoratrx: timestamp (nullable = true)\n",
      " |-- codigoentidad: long (nullable = true)\n",
      " |-- nombreentidad: string (nullable = true)\n",
      " |-- codigositio: long (nullable = true)\n",
      " |-- nombresitio: string (nullable = true)\n",
      " |-- nrotarjeta: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "adl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
